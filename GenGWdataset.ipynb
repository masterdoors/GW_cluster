{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the clusterization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "sents = []\n",
    "for filename in os.listdir(\"sentences\"):\n",
    "    if filename.endswith(\".pkl\"):\n",
    "        with open(\"sentences/\"+filename,'rb') as f:\n",
    "            sents.append(pickle.load(f))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conll data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pdconll = pandas.read_pickle(\"Graph_clustering/pdconll_updated.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>row_num</th>\n",
       "      <th>concomp</th>\n",
       "      <th>text</th>\n",
       "      <th>new_id</th>\n",
       "      <th>new_links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>role=Location|fn=Temporal_collocation|id0=1|ha...</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>_</td>\n",
       "      <td>Location</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>vn:34_review</td>\n",
       "      <td>review.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>vncls=34|number=SG|id0=5|hasExtArg=yes|vn=vn:3...</td>\n",
       "      <td>_</td>\n",
       "      <td>1,6</td>\n",
       "      <td>_</td>\n",
       "      <td>Argument2,Argument1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>attribute</td>\n",
       "      <td>attribute.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>manner=applied|clause_type=DECL|id0=45|hasExtA...</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>vn:11.3_take</td>\n",
       "      <td>take.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>vncls=11.3|fn=Capacity|id0=20|hasExtArg=yes|pl...</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>Argument2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>misanthrope</td>\n",
       "      <td>misanthrope.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>number=SG|id0=9|hasExtArg=no|vn=misanthrope|pl...</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>Argument2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>7</td>\n",
       "      <td>influence</td>\n",
       "      <td>influence.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>fn=Talking_into|id0=8|hasExtArg=yes|member=A1|...</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>_</td>\n",
       "      <td>Set</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>39278</td>\n",
       "      <td>685513</td>\n",
       "      <td>39265</td>\n",
       "      <td>1878</td>\n",
       "      <td>1176</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>8</td>\n",
       "      <td>bidder</td>\n",
       "      <td>bidder.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>number=SG|id0=16|hasExtArg=yes|vn=bidder|lex=b...</td>\n",
       "      <td>_</td>\n",
       "      <td>11,6</td>\n",
       "      <td>_</td>\n",
       "      <td>Argument2,Argument2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>39278</td>\n",
       "      <td>685514</td>\n",
       "      <td>39265</td>\n",
       "      <td>1878</td>\n",
       "      <td>1177</td>\n",
       "      <td>1180,1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>9</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>perhaps.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>id0=12|hasExtArg=no|vn=perhaps|lex=perhaps_RB_...</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>39278</td>\n",
       "      <td>685515</td>\n",
       "      <td>39265</td>\n",
       "      <td>1878</td>\n",
       "      <td>1178</td>\n",
       "      <td>-39265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>10</td>\n",
       "      <td>vn:48.1.1_outcome</td>\n",
       "      <td>outcome.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>vncls=48.1.1|number=SG|id0=10|hasExtArg=no|vn=...</td>\n",
       "      <td>_</td>\n",
       "      <td>7</td>\n",
       "      <td>_</td>\n",
       "      <td>Argument2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>39278</td>\n",
       "      <td>685516</td>\n",
       "      <td>39265</td>\n",
       "      <td>1878</td>\n",
       "      <td>1179</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>11</td>\n",
       "      <td>vn:13.5.1_win</td>\n",
       "      <td>win.01</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>vncls=13.5.1|fn=Getting|id0=15|hasExtArg=yes|l...</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>39278</td>\n",
       "      <td>685517</td>\n",
       "      <td>39265</td>\n",
       "      <td>1878</td>\n",
       "      <td>1180</td>\n",
       "      <td>-39265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685518 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                  1               2  3  4  5  \\\n",
       "index                                                   \n",
       "0       1                 in           in.01  _  _  _   \n",
       "0       2       vn:34_review       review.01  _  _  _   \n",
       "0       3          attribute    attribute.01  _  _  _   \n",
       "0       4       vn:11.3_take         take.01  _  _  _   \n",
       "0       5        misanthrope  misanthrope.01  _  _  _   \n",
       "...    ..                ...             ... .. .. ..   \n",
       "39278   7          influence    influence.01  _  _  _   \n",
       "39278   8             bidder       bidder.01  _  _  _   \n",
       "39278   9            perhaps      perhaps.01  _  _  _   \n",
       "39278  10  vn:48.1.1_outcome      outcome.01  _  _  _   \n",
       "39278  11      vn:13.5.1_win          win.01  _  _  _   \n",
       "\n",
       "                                                       6  7     8  9  \\\n",
       "index                                                                  \n",
       "0      role=Location|fn=Temporal_collocation|id0=1|ha...  _     3  _   \n",
       "0      vncls=34|number=SG|id0=5|hasExtArg=yes|vn=vn:3...  _   1,6  _   \n",
       "0      manner=applied|clause_type=DECL|id0=45|hasExtA...  _     0  _   \n",
       "0      vncls=11.3|fn=Capacity|id0=20|hasExtArg=yes|pl...  _     2  _   \n",
       "0      number=SG|id0=9|hasExtArg=no|vn=misanthrope|pl...  _     2  _   \n",
       "...                                                  ... ..   ... ..   \n",
       "39278  fn=Talking_into|id0=8|hasExtArg=yes|member=A1|...  _     5  _   \n",
       "39278  number=SG|id0=16|hasExtArg=yes|vn=bidder|lex=b...  _  11,6  _   \n",
       "39278  id0=12|hasExtArg=no|vn=perhaps|lex=perhaps_RB_...  _     0  _   \n",
       "39278  vncls=48.1.1|number=SG|id0=10|hasExtArg=no|vn=...  _     7  _   \n",
       "39278  vncls=13.5.1|fn=Getting|id0=15|hasExtArg=yes|l...  _     0  _   \n",
       "\n",
       "                        10 11 12 13  sent_num  row_num concomp  text new_id  \\\n",
       "index                                                                         \n",
       "0                 Location  _  _  _         0        0       1     0      1   \n",
       "0      Argument2,Argument1  _  _  _         0        1       1     0      2   \n",
       "0                     ROOT  _  _  _         0        2       1     0      3   \n",
       "0                Argument2  _  _  _         0        3       1     0      4   \n",
       "0                Argument2  _  _  _         0        4       1     0      5   \n",
       "...                    ... .. .. ..       ...      ...     ...   ...    ...   \n",
       "39278                  Set  _  _  _     39278   685513   39265  1878   1176   \n",
       "39278  Argument2,Argument2  _  _  _     39278   685514   39265  1878   1177   \n",
       "39278                 ROOT  _  _  _     39278   685515   39265  1878   1178   \n",
       "39278            Argument2  _  _  _     39278   685516   39265  1878   1179   \n",
       "39278                 ROOT  _  _  _     39278   685517   39265  1878   1180   \n",
       "\n",
       "       new_links  \n",
       "index             \n",
       "0              3  \n",
       "0            1,6  \n",
       "0             -1  \n",
       "0              2  \n",
       "0              2  \n",
       "...          ...  \n",
       "39278       1174  \n",
       "39278  1180,1175  \n",
       "39278     -39265  \n",
       "39278       1176  \n",
       "39278     -39265  \n",
       "\n",
       "[685518 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdconll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node type list, token vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_types = []\n",
    "tok_vocab = {}\n",
    "for _,row in pdconll.iterrows():\n",
    "    ent_types += row[10].upper().split(\",\")\n",
    "    w = row[2][:row[2].find(\".\")]\n",
    "    if w not in tok_vocab:\n",
    "        tok_vocab[w] = len(w)   \n",
    "    \n",
    "ent_types = set(ent_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each text:\n",
    "#1. Make \"Title\" from the first sentence\n",
    "#For the remaining ones:\n",
    "#2. Enumerate Entities;\n",
    "#3. Enumerate <Entity Types>\n",
    "#4. Enumerate E-Rel-E tuples;\n",
    "#5. Generate the text of the sentence with <entitytype_N>\n",
    "#6. Generate word_ids of the text with \"-1\"s instead of the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt_file(filename):\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            yield line.strip().split(\" - \",1)\n",
    "            \n",
    "parser = parse_txt_file(\"Graph_clustering/CoNLL2009-ST-train-English_sentences_numbered.txt\")            \n",
    "full_texts = pandas.DataFrame(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In an Oct. 19 review of `` The Misanthrope '' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ms. Haag plays Elianti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Rolls - Royce Motor Cars Inc. said it expects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The luxury auto maker last year sold 1,214 car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Howard Mosher , president and chief executive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39274</td>\n",
       "      <td>39274</td>\n",
       "      <td>But if the board rejects a reduced bid and dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39275</td>\n",
       "      <td>39275</td>\n",
       "      <td>The pilots could play hardball by noting they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39276</td>\n",
       "      <td>39276</td>\n",
       "      <td>If they were to insist on a low bid of , say $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39277</td>\n",
       "      <td>39277</td>\n",
       "      <td>Also , because UAL Chairman Stephen Wolf and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39278</td>\n",
       "      <td>39278</td>\n",
       "      <td>That could cost him the chance to influence th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1\n",
       "0          0  In an Oct. 19 review of `` The Misanthrope '' ...\n",
       "1          1                           Ms. Haag plays Elianti .\n",
       "2          2  Rolls - Royce Motor Cars Inc. said it expects ...\n",
       "3          3  The luxury auto maker last year sold 1,214 car...\n",
       "4          4  Howard Mosher , president and chief executive ...\n",
       "...      ...                                                ...\n",
       "39274  39274  But if the board rejects a reduced bid and dec...\n",
       "39275  39275  The pilots could play hardball by noting they ...\n",
       "39276  39276  If they were to insist on a low bid of , say $...\n",
       "39277  39277  Also , because UAL Chairman Stephen Wolf and o...\n",
       "39278  39278  That could cost him the chance to influence th...\n",
       "\n",
       "[39279 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getOrder(full_texts,sid,txt):\n",
    "    s_txt = full_texts.iloc[sid][1].lower()\n",
    "    flag = True\n",
    "    order = list(range(len(txt)))\n",
    "    \n",
    "    while flag:\n",
    "        flag = False\n",
    "        for i in range(len(txt)-1):\n",
    "            t1_pos = s_txt.find(txt[i])\n",
    "            t2_pos = s_txt.find(txt[i+1])\n",
    "            \n",
    "            if t1_pos > -1 and t2_pos > -1:\n",
    "                if t2_pos < t1_pos:\n",
    "                    t = txt[i]\n",
    "                    txt[i] = txt[i+1]\n",
    "                    txt[i+1] = t\n",
    "                    \n",
    "                    t = order[i]\n",
    "                    order[i] = order[i+1]\n",
    "                    order[i+1] = t\n",
    "                    flag = True\n",
    "    return order        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy\n",
    "\n",
    "def leaveUniq(txt):\n",
    "    parts = set(txt.split(\",\"))\n",
    "    return \",\".join(list(parts))\n",
    "    \n",
    "\n",
    "#buid dict. {tok_id}->{tok_id}->rel_type\n",
    "#+leave only one cluster per real sentence\n",
    "def preprocessSents(pd,sents):\n",
    "    print(\"Preprocessing..\")\n",
    "    #useful indexes\n",
    "    sdict_inv = {}\n",
    "    sdict_dir = {}\n",
    "    for i,s in enumerate(sents):\n",
    "        for t_id in s:\n",
    "            if t_id not in sdict_inv:\n",
    "                sdict_inv[t_id] = []\n",
    "            sdict_inv[t_id].append(i)\n",
    "            if i not in sdict_dir:\n",
    "                sdict_dir[i] = []\n",
    "            sdict_dir[i].append(t_id)\n",
    "                \n",
    "    #first pass. build real_sent->gen_sents dict\n",
    "    rsent2sent = {}\n",
    "    print (\"First pass\")\n",
    "    with tqdm(total=len(pd)) as pbar: \n",
    "        for _,row in pd.iterrows():\n",
    "            s_id = row['sent_num']\n",
    "            if row['new_id'] in sdict_inv:\n",
    "                cl_ids = sdict_inv[row['new_id']]\n",
    "                if s_id not in rsent2sent:\n",
    "                    rsent2sent[s_id] = {}\n",
    "                for cl_id in cl_ids:    \n",
    "                    if cl_id not in rsent2sent[s_id]:\n",
    "                        rsent2sent[s_id][cl_id] = []\n",
    "                    rsent2sent[s_id][cl_id].append(row['new_id'])\n",
    "            pbar.update(1)\n",
    "            \n",
    "    #remove ambiguation. Just leave the biggest ones\n",
    "    rsent2sent_filtered = {}\n",
    "    for s_id in rsent2sent:\n",
    "        if len(rsent2sent[s_id]) > 1:\n",
    "            max_id = list(rsent2sent[s_id].keys())[0]\n",
    "            for cl_id in rsent2sent[s_id]:\n",
    "                if len(rsent2sent[s_id][cl_id]) > len(rsent2sent[s_id][max_id]):\n",
    "                    max_id = cl_id\n",
    "            rsent2sent_filtered[s_id] = rsent2sent[s_id][max_id]        \n",
    "        else:\n",
    "            rsent2sent_filtered[s_id] = list(rsent2sent[s_id].values())[0]\n",
    "    \n",
    "    #second pass. build dict \n",
    "    res_dict = {}\n",
    "    rel_vocab = {}\n",
    "    print (\"Second pass\")\n",
    "    pd=pd.reset_index().set_index(['new_id','sent_num'])\n",
    "    with tqdm(total=len(rsent2sent_filtered)) as pbar: \n",
    "        for s_id in rsent2sent_filtered:\n",
    "            ents = rsent2sent_filtered[s_id]\n",
    "            ents_set = set(ents)\n",
    "            for e in ents:\n",
    "                e_row = pd.loc[[e,s_id]]\n",
    "                #print (e_row['new_links'].iloc[0])\n",
    "                \n",
    "                #print (e_row)\n",
    "                e_links = e_row['new_links'].iloc[0].split(\",\")\n",
    "\n",
    "                for l in e_links:\n",
    "                    if l in ents_set and l > \"-1\":\n",
    "                        if e not in res_dict:\n",
    "                            res_dict[e] = {}\n",
    "                        l_row = pd.loc[[l,s_id]]\n",
    "                        link_type = leaveUniq(l_row[10].iloc[0]) + \"_\" + leaveUniq(e_row[10].iloc[0])\n",
    "                        if link_type not in rel_vocab:\n",
    "                            rel_vocab[link_type] = len(rel_vocab)\n",
    "\n",
    "                        res_dict[e][l] = link_type\n",
    "            pbar.update(1) \n",
    "            #break\n",
    "    return res_dict, rel_vocab\n",
    "    \n",
    "\n",
    "def genIds(txt,tok_vocab):\n",
    "    return \" \".join([str(tok_vocab.get(t,\"-1\")) for t in txt])\n",
    "        \n",
    "def process_conll(pd,rel_vocab,tok_vocab,sents):\n",
    "    cur_sent_num = None\n",
    "    cur_txt_num = None\n",
    "\n",
    "    collect_title = False\n",
    "    title = []\n",
    "    t_sent = -1\n",
    "    txt = []\n",
    "    p_txt = []\n",
    "    rels = []\n",
    "    ents = {}\n",
    "    ent_strs = []\n",
    "    ent2num = {}\n",
    "    ent_types = []\n",
    "    \n",
    "    datas = []\n",
    "    print(\"Building...\")\n",
    "\n",
    "    with tqdm(total=len(pd)) as pbar: \n",
    "        for _,row in pd.iterrows():\n",
    "            text_num = row[\"text\"]\n",
    "            sent_num = row[\"sent_num\"]\n",
    "            if cur_sent_num != None and sent_num != cur_sent_num:\n",
    "                #Generate line for the output\n",
    "                if not collect_title:\n",
    "                    if len(ent2num) > 0:\n",
    "                        processed = {}\n",
    "                        for sid in list(ent2num.keys()):\n",
    "                            sentence = sents[sid]\n",
    "                            if sid in ent2num:\n",
    "                                if sid not in processed:\n",
    "                                    processed[sid] = True\n",
    "                                    for s in sentence:\n",
    "                                        if s in ent2num:\n",
    "                                            processed[s] = True\n",
    "                                            #print(sid,s,ent2num)\n",
    "                                            rels.append(str(ent2num[sid]) + \" \" + str(rel_vocab[sentence[s]]) + \" \" + str(ent2num[s]))\n",
    "\n",
    "                    \n",
    "                    if len(rels) > 0:\n",
    "                        tmp = []\n",
    "                        order2 = getOrder(full_texts,t_sent,title)\n",
    "                        \n",
    "                        #tmp.append(\" \".join(list(numpy.asarray(title)[order2])))\n",
    "                        tmp.append(\" \".join(title))\n",
    "                        tmp.append(\" ; \".join(ent_strs))\n",
    "                        tmp.append(\" \".join(ent_types))\n",
    "                        tmp.append(\" ; \".join(rels))\n",
    "                        \n",
    "                        order = getOrder(full_texts,sent_num,p_txt)\n",
    "                        \n",
    "                        #tmp.append(\" \".join(list(numpy.asarray(txt)[order])))\n",
    "                        tmp.append(\" \".join(txt))\n",
    "                        tmp.append(genIds(txt,tok_vocab))\n",
    "                        datas.append(tmp)\n",
    "        \n",
    "                    txt = []\n",
    "                    p_txt = [] \n",
    "                    rels = []\n",
    "                    ents = {}\n",
    "                    ent_strs = []\n",
    "                    ent2num = {}\n",
    "                    ent_types = [] \n",
    "                else:\n",
    "                    collect_title  = False\n",
    "\n",
    "                cur_sent_num = sent_num\n",
    "            #else:    \n",
    "            if text_num != cur_txt_num:\n",
    "                cur_txt_num = text_num \n",
    "                collect_title = True\n",
    "                cur_sent_num = sent_num\n",
    "                title = []\n",
    "\n",
    "            if collect_title:\n",
    "                #collect first sentence as a title\n",
    "                t_sent = sent_num\n",
    "                if row[2].find(\".\") == -1:\n",
    "                    title.append(row[1].lower())\n",
    "                else:    \n",
    "                    title.append(row[2][:row[2].find(\".\")].lower())                    \n",
    "            else:\n",
    "                tok_id = row['new_id']\n",
    "                #if it is entity - add it\n",
    "                if tok_id in sents:\n",
    "                    #remove duplicates, replace \",\" to \"_\"\n",
    "                    ent_type = \"_\".join(list(set(row[10].split(\",\"))))\n",
    "                    ent_str = \"<\" + ent_type + \">\"\n",
    "                    #if ent_str not in ents:\n",
    "                    #    ents[ent_str] = []\n",
    "                    #ents[ent_str] = tok_id   \n",
    "                    ent2num[tok_id] = len(ent2num)\n",
    "                    if row[2].find(\".\") == -1:\n",
    "                        ent_strs.append(row[1].lower())\n",
    "                    else:    \n",
    "                        ent_strs.append(row[2][:row[2].find(\".\")].lower())\n",
    "                    ent_types.append(ent_str)\n",
    "                    txt.append(\"<\" + ent_type + \"_\"+ str(len(ent2num)-1) +\">\")\n",
    "                else:\n",
    "                    if row[2].find(\".\") == -1:\n",
    "                        txt.append(row[1].lower())\n",
    "                    else:    \n",
    "                        txt.append(row[2][:row[2].find(\".\")].lower())\n",
    "                        \n",
    "                if row[2].find(\".\") == -1:\n",
    "                    p_txt.append(row[1].lower())\n",
    "                else:    \n",
    "                    p_txt.append(row[2][:row[2].find(\".\")].lower())                        \n",
    "\n",
    "            pbar.update(1)    \n",
    "            #print (collect_title)\n",
    "            \n",
    "    return pandas.DataFrame(datas),datas            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/685518 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing..\n",
      "First pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 685518/685518 [02:13<00:00, 5133.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34487/34487 [1:24:31<00:00,  6.80it/s]   \n"
     ]
    }
   ],
   "source": [
    "dsents, rel_vocab = preprocessSents(pdconll,sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/685518 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 685518/685518 [02:39<00:00, 4287.01it/s]\n"
     ]
    }
   ],
   "source": [
    "gw_dataset, datas = process_conll(pdconll,rel_vocab,tok_vocab,dsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>say rolls - royce motor car car inc. in it exp...</td>\n",
       "      <td>mosher ; executive ; chief ; he ; growth ; and...</td>\n",
       "      <td>&lt;Argument1&gt; &lt;Elaboration&gt; &lt;Elaboration&gt; &lt;Argum...</td>\n",
       "      <td>5 18 4 ; 6 19 5 ; 7 19 5 ; 9 21 10</td>\n",
       "      <td>howard &lt;Argument1_0&gt; and say officer president...</td>\n",
       "      <td>-1 -1 3 3 7 9 10 -1 -1 -1 -1 -1 3 -1 -1 -1 3 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>investor to appeal and exchange commission not...</td>\n",
       "      <td>proposal ; ease ; undermine ; for ; and ; comp...</td>\n",
       "      <td>&lt;Argument1&gt; &lt;Argument3&gt; &lt;Argument2&gt; &lt;ROOT&gt; &lt;Ar...</td>\n",
       "      <td>9 18 8 ; 10 19 9 ; 11 19 9</td>\n",
       "      <td>&lt;Argument1_0&gt; &lt;Argument3_1&gt; sec &lt;Argument2_2&gt; ...</td>\n",
       "      <td>-1 -1 -1 -1 11 10 7 9 -1 11 2 -1 9 5 4 7 8 -1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>investor to appeal and exchange commission not...</td>\n",
       "      <td>in ; about ; change ; from ; executive ; among...</td>\n",
       "      <td>&lt;Location&gt; &lt;NonCore&gt; &lt;Argument2_Argument1&gt; &lt;No...</td>\n",
       "      <td>0 21 1 ; 7 11 3 ; 8 25 4 ; 9 1 5 ; 10 8 7 ; 11...</td>\n",
       "      <td>they make &lt;Location_0&gt; argument letter agency ...</td>\n",
       "      <td>4 4 -1 8 6 6 -1 -1 4 6 7 -1 -1 -1 -1 -1 -1 4 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>investor to appeal and exchange commission not...</td>\n",
       "      <td>change ; allow ; report ; executive ; exercise...</td>\n",
       "      <td>&lt;Argument2_Argument1&gt; &lt;Argument1&gt; &lt;Argument2&gt; ...</td>\n",
       "      <td>2 26 1 ; 3 17 2 ; 4 8 2 ; 5 9 2 ; 6 8 4 ; 7 28...</td>\n",
       "      <td>&lt;Argument2_Argument1_0&gt; &lt;Argument1_1&gt; propose ...</td>\n",
       "      <td>-1 -1 7 -1 4 -1 -1 -1 -1 -1 -1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>investor to appeal and exchange commission not...</td>\n",
       "      <td>many ; and ; shake ; prompt ; stack ; individu...</td>\n",
       "      <td>&lt;Argument1&gt; &lt;Argument2&gt; &lt;Set_Argument1&gt; &lt;Elabo...</td>\n",
       "      <td>2 54 1 ; 3 16 1 ; 4 54 1</td>\n",
       "      <td>&lt;Argument1_0&gt; maintain of &lt;Argument2_1&gt; letter...</td>\n",
       "      <td>-1 8 2 -1 7 -1 -1 -1 5 10 2 8 -1 3 6 7 7 2 6 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22325</td>\n",
       "      <td>donald trump withdraw face doubt his before $ ...</td>\n",
       "      <td>8 ; million ; in ; financing</td>\n",
       "      <td>&lt;ROOT&gt; &lt;ROOT&gt; &lt;ROOT&gt; &lt;Argument1&gt;</td>\n",
       "      <td>1 15 0 ; 2 15 0 ; 3 81 1</td>\n",
       "      <td>together receive and $ raise chase citicorp &lt;R...</td>\n",
       "      <td>8 7 3 1 5 5 -1 -1 -1 -1 4 3 -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22326</td>\n",
       "      <td>donald trump withdraw face doubt his before $ ...</td>\n",
       "      <td>break ; coalition ; now ; of ; and ; longtime ...</td>\n",
       "      <td>&lt;ROOT&gt; &lt;Argument1&gt; &lt;Time&gt; &lt;ROOT&gt; &lt;Argument2&gt; &lt;...</td>\n",
       "      <td>1 8 0 ; 2 54 1 ; 3 39 1 ; 4 61 3 ; 7 50 6</td>\n",
       "      <td>in addition &lt;ROOT_0&gt; &lt;Argument1_1&gt; apart &lt;Time...</td>\n",
       "      <td>2 8 -1 -1 5 -1 -1 -1 10 5 5 -1 4 -1 5 -1 4 2 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22327</td>\n",
       "      <td>donald trump withdraw face doubt his before $ ...</td>\n",
       "      <td>outside ; in ; top ; chicago ; meeting</td>\n",
       "      <td>&lt;Location&gt; &lt;Location&gt; &lt;ROOT&gt; &lt;Argument2&gt; &lt;Argu...</td>\n",
       "      <td>1 49 0 ; 4 15 2</td>\n",
       "      <td>group resilience 's get today test convene fir...</td>\n",
       "      <td>5 10 2 3 5 4 7 5 3 6 -1 -1 5 2 -1 -1 -1 5 8 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22328</td>\n",
       "      <td>donald trump withdraw face doubt his before $ ...</td>\n",
       "      <td>member ; overwhelmingly ; why ; explain ; last...</td>\n",
       "      <td>&lt;Argument1&gt; &lt;Manner&gt; &lt;Purpose&gt; &lt;Argument2&gt; &lt;RO...</td>\n",
       "      <td>1 7 2 ; 3 39 2 ; 4 54 2 ; 5 100 4 ; 6 49 3 ; 7...</td>\n",
       "      <td>buy out finance approve banks refuse week &lt;Arg...</td>\n",
       "      <td>3 3 7 7 5 6 4 -1 -1 -1 -1 -1 -1 -1 4 -1 -1 5 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22329</td>\n",
       "      <td>donald trump withdraw face doubt his before $ ...</td>\n",
       "      <td>$ ; say ; transaction ; other ; share ; 200</td>\n",
       "      <td>&lt;Argument2_Argument1&gt; &lt;Elaboration&gt; &lt;Argument2...</td>\n",
       "      <td>0 64 2 ; 1 11 0 ; 3 17 2 ; 4 8 2 ; 5 97 2</td>\n",
       "      <td>if insist able on they board because obtain no...</td>\n",
       "      <td>2 6 4 2 4 5 7 6 3 3 8 5 4 3 2 5 7 6 6 -1 -1 -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22330 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0      say rolls - royce motor car car inc. in it exp...   \n",
       "1      investor to appeal and exchange commission not...   \n",
       "2      investor to appeal and exchange commission not...   \n",
       "3      investor to appeal and exchange commission not...   \n",
       "4      investor to appeal and exchange commission not...   \n",
       "...                                                  ...   \n",
       "22325  donald trump withdraw face doubt his before $ ...   \n",
       "22326  donald trump withdraw face doubt his before $ ...   \n",
       "22327  donald trump withdraw face doubt his before $ ...   \n",
       "22328  donald trump withdraw face doubt his before $ ...   \n",
       "22329  donald trump withdraw face doubt his before $ ...   \n",
       "\n",
       "                                                       1  \\\n",
       "0      mosher ; executive ; chief ; he ; growth ; and...   \n",
       "1      proposal ; ease ; undermine ; for ; and ; comp...   \n",
       "2      in ; about ; change ; from ; executive ; among...   \n",
       "3      change ; allow ; report ; executive ; exercise...   \n",
       "4      many ; and ; shake ; prompt ; stack ; individu...   \n",
       "...                                                  ...   \n",
       "22325                       8 ; million ; in ; financing   \n",
       "22326  break ; coalition ; now ; of ; and ; longtime ...   \n",
       "22327             outside ; in ; top ; chicago ; meeting   \n",
       "22328  member ; overwhelmingly ; why ; explain ; last...   \n",
       "22329        $ ; say ; transaction ; other ; share ; 200   \n",
       "\n",
       "                                                       2  \\\n",
       "0      <Argument1> <Elaboration> <Elaboration> <Argum...   \n",
       "1      <Argument1> <Argument3> <Argument2> <ROOT> <Ar...   \n",
       "2      <Location> <NonCore> <Argument2_Argument1> <No...   \n",
       "3      <Argument2_Argument1> <Argument1> <Argument2> ...   \n",
       "4      <Argument1> <Argument2> <Set_Argument1> <Elabo...   \n",
       "...                                                  ...   \n",
       "22325                   <ROOT> <ROOT> <ROOT> <Argument1>   \n",
       "22326  <ROOT> <Argument1> <Time> <ROOT> <Argument2> <...   \n",
       "22327  <Location> <Location> <ROOT> <Argument2> <Argu...   \n",
       "22328  <Argument1> <Manner> <Purpose> <Argument2> <RO...   \n",
       "22329  <Argument2_Argument1> <Elaboration> <Argument2...   \n",
       "\n",
       "                                                       3  \\\n",
       "0                     5 18 4 ; 6 19 5 ; 7 19 5 ; 9 21 10   \n",
       "1                             9 18 8 ; 10 19 9 ; 11 19 9   \n",
       "2      0 21 1 ; 7 11 3 ; 8 25 4 ; 9 1 5 ; 10 8 7 ; 11...   \n",
       "3      2 26 1 ; 3 17 2 ; 4 8 2 ; 5 9 2 ; 6 8 4 ; 7 28...   \n",
       "4                               2 54 1 ; 3 16 1 ; 4 54 1   \n",
       "...                                                  ...   \n",
       "22325                           1 15 0 ; 2 15 0 ; 3 81 1   \n",
       "22326          1 8 0 ; 2 54 1 ; 3 39 1 ; 4 61 3 ; 7 50 6   \n",
       "22327                                    1 49 0 ; 4 15 2   \n",
       "22328  1 7 2 ; 3 39 2 ; 4 54 2 ; 5 100 4 ; 6 49 3 ; 7...   \n",
       "22329          0 64 2 ; 1 11 0 ; 3 17 2 ; 4 8 2 ; 5 97 2   \n",
       "\n",
       "                                                       4  \\\n",
       "0      howard <Argument1_0> and say officer president...   \n",
       "1      <Argument1_0> <Argument3_1> sec <Argument2_2> ...   \n",
       "2      they make <Location_0> argument letter agency ...   \n",
       "3      <Argument2_Argument1_0> <Argument1_1> propose ...   \n",
       "4      <Argument1_0> maintain of <Argument2_1> letter...   \n",
       "...                                                  ...   \n",
       "22325  together receive and $ raise chase citicorp <R...   \n",
       "22326  in addition <ROOT_0> <Argument1_1> apart <Time...   \n",
       "22327  group resilience 's get today test convene fir...   \n",
       "22328  buy out finance approve banks refuse week <Arg...   \n",
       "22329  if insist able on they board because obtain no...   \n",
       "\n",
       "                                                       5  \n",
       "0      -1 -1 3 3 7 9 10 -1 -1 -1 -1 -1 3 -1 -1 -1 3 -...  \n",
       "1      -1 -1 -1 -1 11 10 7 9 -1 11 2 -1 9 5 4 7 8 -1 ...  \n",
       "2      4 4 -1 8 6 6 -1 -1 4 6 7 -1 -1 -1 -1 -1 -1 4 -...  \n",
       "3                       -1 -1 7 -1 4 -1 -1 -1 -1 -1 -1 4  \n",
       "4      -1 8 2 -1 7 -1 -1 -1 5 10 2 8 -1 3 6 7 7 2 6 4...  \n",
       "...                                                  ...  \n",
       "22325                     8 7 3 1 5 5 -1 -1 -1 -1 4 3 -1  \n",
       "22326  2 8 -1 -1 5 -1 -1 -1 10 5 5 -1 4 -1 5 -1 4 2 3...  \n",
       "22327     5 10 2 3 5 4 7 5 3 6 -1 -1 5 2 -1 -1 -1 5 8 10  \n",
       "22328  3 3 7 7 5 6 4 -1 -1 -1 -1 -1 -1 -1 4 -1 -1 5 -...  \n",
       "22329  2 6 4 2 4 5 7 6 3 3 8 5 4 3 2 5 7 6 6 -1 -1 -1...  \n",
       "\n",
       "[22330 rows x 6 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gw_dataset_train, gw_dataset_test = train_test_split(gw_dataset, test_size=0.2, random_state=1)\n",
    "\n",
    "#gw_dataset_train, gw_dataset_val = train_test_split(gw_dataset_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_dataset.to_csv(\"conll_train.tsv\",header=False,index=False,sep=\"\\t\")\n",
    "#gw_dataset_test.to_csv(\"conll_test.tsv\",header=False,index=False,sep=\"\\t\")\n",
    "#gw_dataset_val.to_csv(\"conll_val.tsv\",header=False,index=False,sep=\"\\t\")\n",
    "\n",
    "with open(\"relations.vocab\",\"w\") as f:\n",
    "    for r in rel_vocab:\n",
    "        f.write(r+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_dataset_train[4].to_csv(\"conll_gold.tsv\",header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = []\n",
    "et2 = []\n",
    "for e in ent_types:\n",
    "    et.append(\"<\"+e+\">\")\n",
    "    et2.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<ROOT>',\n",
       " '<DIRECTION>',\n",
       " '<BENEFACTIVE>',\n",
       " '<ARGUMENT1>',\n",
       " '<ARGUMENT2>',\n",
       " '<ARGUMENT6>',\n",
       " '<ARGUMENT10>',\n",
       " '<MANNER>',\n",
       " '<EXTENT>',\n",
       " '<ELABORATION>',\n",
       " '<SET>',\n",
       " '<ARGUMENT3>',\n",
       " '<LOCATION>',\n",
       " '<ARGUMENT4>',\n",
       " '<NAME>',\n",
       " '<PURPOSE>',\n",
       " '<TIME>',\n",
       " '<NONCORE>']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ROOT',\n",
       " 'DIRECTION',\n",
       " 'BENEFACTIVE',\n",
       " 'ARGUMENT1',\n",
       " 'ARGUMENT2',\n",
       " 'ARGUMENT6',\n",
       " 'ARGUMENT10',\n",
       " 'MANNER',\n",
       " 'EXTENT',\n",
       " 'ELABORATION',\n",
       " 'SET',\n",
       " 'ARGUMENT3',\n",
       " 'LOCATION',\n",
       " 'ARGUMENT4',\n",
       " 'NAME',\n",
       " 'PURPOSE',\n",
       " 'TIME',\n",
       " 'NONCORE']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
